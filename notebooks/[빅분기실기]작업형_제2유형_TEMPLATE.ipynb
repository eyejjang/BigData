{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIUJBqz+7DxUIujA/UKcMH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# LabelEncoder 변환 값 원복 작업\n","df_train_y = pd.read_csv(\"https://raw.githubusercontent.com/eyejjang/BigData/main/dataset_yemoon/datasets/Part5/404_y_train.csv\")\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","df_train_y['Segmentation'] = le.fit_transform(df_train_y['Segmentation'])\n","print(le.classes_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yahROa6d3qTG","executionInfo":{"status":"ok","timestamp":1718773561345,"user_tz":-540,"elapsed":1320,"user":{"displayName":"Eungjun Kim (EYEz)","userId":"08487114634528026899"}},"outputId":"2d0301a4-02f8-4fc8-dde3-96550ea595d1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['A' 'B' 'C' 'D']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSSep9WM3_nm"},"outputs":[],"source":["#import sklearn.preprocessing\n","#print(dir(sklearn.preprocessing))\n","#print(help(sklearn))\n","print(le.classes_)\n","\n","################################################################################\n","## 데이터 파일 읽기\n","!git clone https://github.com/AnalyticsKnight/yemoonsaBigdata\n","import pandas as pd\n","df_train_x = pd.read_csv(\"/content/yemoonsaBigdata/datasets/Part5/404_x_train.csv\")\n","df_train_y = pd.read_csv(\"/content/yemoonsaBigdata/datasets/Part5/404_y_train.csv\")\n","df_test_x = pd.read_csv(\"/content/yemoonsaBigdata/datasets/Part5/404_x_test.csv\")\n","################################################################################\n","## 데이터 확인\n","print(\"## 데이터 확인\")\n","print(df_train_x.info())\n","print(df_train_x.describe(include='all'))\n","print(df_train_x.head())\n","print('*'*100)\n","print(df_test_x.info())\n","print(df_test_x.describe(include='all'))\n","print(df_test_x.head())\n","print('*'*100)\n","################################################################################\n","## 결측치 확인\n","print(\"## 결측치 확인\")\n","print(df_train_x.isna().sum())\n","print(df_test_x.isna().sum())\n","################################################################################\n","## 결측치 처리\n","################################################################################\n","## 컬럼 그룹화\n","col_del = ['ID']\n","col_str = ['Gender','Ever_Married','Graduated','Profession','Spending_Score']\n","col_num = ['Age','Work_Experience','Family_Size']\n","#y = Segmentation\n","################################################################################\n","## 라벨인코팅\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","for i in col_str :\n","    df_train_x[i] = le.fit_transform(df_train_x[i])\n","    df_test_x[i] = le.transform(df_test_x[i])\n","\n","df_train_y['Segmentation'] = le.fit_transform(df_train_y['Segmentation'])\n","\n","## 원 핫 인코딩\n","#df_train_x = pd.get_dummies(df_train_x)\n","#df_test_x = pd.get_dummies(df_test_x)\n","################################################################################\n","## 스케일링\n","from sklearn.preprocessing import MinMaxScaler\n","mm = MinMaxScaler()\n","df_train_x[col_num] = mm.fit_transform(df_train_x[col_num])\n","df_test_x[col_num] = mm.transform(df_test_x[col_num])\n","\n","print(\"## 스케일링 후 확인\")\n","print(df_train_x.head())\n","print(df_test_x.head())\n","################################################################################\n","## 트레이닝셋, 검증셋 분리\n","from sklearn.model_selection import train_test_split\n","train_x, valdn_x, train_y, valdn_y = train_test_split(df_train_x[col_str+col_num], df_train_y['Segmentation'], test_size = 0.2, stratify = df_train_y['Segmentation'])\n","\n","print(\"## 데이터셋 분리 후 확인\")\n","print(train_x.shape)\n","print(valdn_x.shape)\n","print(train_y.shape)\n","print(valdn_y.shape)\n","################################################################################\n","## 랜덤포레스트 모델링(회귀)\n","from sklearn.ensemble import RandomForestRegressor\n","RFR = RandomForestRegressor(random_state=123)\n","RFR.fit(train_x, train_y)\n","\n","## 랜덤포레스트 모델링(분류)\n","from sklearn.ensemble import RandomForestClassifier\n","RFC = RandomForestClassifier(random_state=123)\n","RFC.fit(train_x, train_y)\n","\n","## XG부스트 모델링(회귀)\n","from xgboost import XGBRegressor\n","XGBR = XGBRegressor(random_state=123)\n","XGBR.fit(train_x, train_y)\n","\n","## XG부스트 모델링(분류)\n","from xgboost import XGBClassifier\n","XGBC = XGBClassifier(random_state=123)\n","XGBC.fit(train_x, train_y)\n","################################################################################\n","## 결과값 예측 (분류)\n","print(\"## 결과값 예측\")\n","pred_RFC = RFC.predict(valdn_x)\n","pred_XGBC = XGBC.predict(valdn_x)\n","\n","## F1 스코어(분류)\n","from sklearn.metrics import f1_score\n","score_RFC = f1_score(valdn_y, pred_RFC, average='macro')\n","score_XGBC = f1_score(valdn_y, pred_XGBC, average='macro')\n","\n","## Accuracy(분류)\n","from sklearn.metrics import accuracy_score\n","score_RFC = accuracy_score(valdn_y, pred_RFC, average='macro')\n","score_XGBC = accuracy_score(valdn_y, pred_XGBC, average='macro')\n","\n","## Recall(분류)\n","from sklearn.metrics import recall_score\n","score_RFC = recall_score(valdn_y, pred_RFC, average='macro')\n","score_XGBC = recall_score(valdn_y, pred_XGBC, average='macro')\n","\n","## Precision(분류)\n","from sklearn.metrics import precision_score\n","score_RFC = precision_score(valdn_y, pred_RFC, average='macro')\n","score_XGBC = precision_score(valdn_y, pred_XGBC, average='macro')\n","\n","print('score_RFC: ', score_RFC)\n","print('score_XGBC: ', score_XGBC)\n","################################################################################\n","## 결과값 예측 (분류-확률)\n","print(\"## 결과값 예측\")\n","pred_RFC = RFC.predict_proba(valdn_x)[:,1]\n","pred_XGBC = XGBC.predict_proba(valdn_x)[:,1]\n","\n","## ROC_AUC 확인\n","from sklearn.metrics import roc_auc_score\n","score_RFC = roc_auc_score(valdn_y, pred_RFC)\n","print('ROC_AUC_RFC_valdn: ', score_RFC)\n","score_XGBC = roc_auc_score(valdn_y, pred_XGBC)\n","print('ROC_AUC_XGBC_valdn: ', score_XGBC)\n","################################################################################\n","## 결과값 예측 (회귀)\n","print(\"## 결과값 예측\")\n","pred_RFR = RFR.predict(valdn_x)\n","pred_XGBR = XGBR.predict(valdn_x)\n","\n","## MAE (회귀)\n","from sklearn.metrics import mean_absolute_error\n","mae_RFR = mean_absolute_error(valdn_y, pred_RFR)\n","mae_XGBR = mean_absolute_error(valdn_y, pred_XGBR)\n","print('RMSE_RFR:', mae_RFR)\n","print('RMSE_XGBR:', mae_XGBR)\n","\n","## MSE (회귀)\n","from sklearn.metrics import mean_squared_error\n","mse_RFR = mean_squared_error(valdn_y, pred_RFR)\n","mse_XGBR = mean_squared_error(valdn_y, pred_XGBR)\n","print('RMSE_RFR:', mse_RFR)\n","print('RMSE_XGBR:', mse_XGBR)\n","\n","## RMSE (회귀)\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","rmse_RFR = np.sqrt(mean_squared_error(valdn_y, pred_RFR))\n","rmse_XGBR = np.sqrt(mean_squared_error(valdn_y, pred_XGBR))\n","print('RMSE_RFR:', rmse_RFR)\n","print('RMSE_XGBR:', rmse_XGBR)\n","################################################################################\n","## 결과 데이터프레임 생성\n","pred_RFC = RFC.predict(df_test_x[col_str+col_num])\n","y_test_RFC = le.inverse_transform(pred_RFC)\n","result = pd.DataFrame({'ID':df_test_x['ID'], 'Segmentation':y_test_RFC})\n","print(result)\n","################################################################################\n","## 결과값 파일 저장\n","result.to_csv('04_02.csv', index=False)\n","################################################################################"]}]}